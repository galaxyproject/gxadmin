#!/bin/bash
usage(){
	echo "gxadmin usage:"
	cmds="$(grep -o '## .*' $0 | grep -v grep | sort | sed 's/^## //g')"
	echo
	echo "Zergling Commands:"
	echo
	echo "$cmds" | grep '^zerg' | column -s: -t | sed 's/^/    /'
	echo
	echo "Handler Commands:"
	echo
	echo "$cmds" | grep '^handler' | column -s: -t | sed 's/^/    /'
	echo
	echo "DB Queries:"
	echo
	echo "$cmds" | grep 'query ' | sort -k2 | column -s: -t | sed 's/^/    /'
	echo
	echo "Other:"
	echo
	echo "$cmds" | grep -v 'query ' | grep -v '^zerg' | grep -v handler | column -s: -t | sed 's/^/    /'
	echo
	echo "help / -h / --help : this message"
	if [[ $1 == "safe" ]]; then
		exit 0;
	fi
	exit 1
}

assert_restart_lock(){
	if [ -f /usr/local/galaxy/galaxy-dist/.restart-lock ]; then
		echo "A restart lock exists. This means someone is probably already restarting galaxy."
		exit 3
	fi
}

error() {
	echo -e "\e[48;5;09m$@\e[m"
}

success() {
	echo -e "\e[38;5;40m$@\e[m"
}

validate() {
	cd $GALAXY_DIST
	fail_count=0
	for file in $GALAXY_DIST/*.xml; do
		xmllint $file > /dev/null 2>/dev/null;
		exit_code=$?
		if (( $exit_code > 0 )); then
			fail_count=$(echo "$fail_count + 1" | bc)
			error "  FAIL: $file ($exit_code)";
		else
			success "  OK: $file";
		fi
	done;

	for file in $GALAXY_DIST/config/*.xml; do
		xmllint $file > /dev/null 2>/dev/null;
		exit_code=$?
		if (( $exit_code > 0 )); then
			fail_count=$(echo "$fail_count + 1" | bc)
			error "  FAIL: $file ($exit_code)";
		else
			success "  OK: $file";
		fi
	done;
	cd -

	if (( fail_count == 0 )); then
		success "All XML files validated"
	else
		error "XML validation failed, cancelling any actions."
		exit 1
	fi
}

zerg_swap() {
	user_message=$1

	# Ensure that we lock out other users.
	assert_restart_lock

	zerg0running=0
	supervisorctl status gx:zergling0 | grep RUNNING
	zerg0=$?
	if (( $zerg0 == 0 )); then
		echo "zerg 0 is running"
		zerg0running=1
	fi

	zerg1running=0
	supervisorctl status gx:zergling1 | grep RUNNING
	zerg1=$?
	if [ "$zerg1" -eq "0" ]; then
		echo "zerg 1 is running"
		zerg1running=1
	fi

	if [[ "$zerg1running" -eq "1" && "$zerg0running" -eq "1" ]] ; then
		error "ERROR: BOTH ARE RUNNING"
		exit 2
	fi
	if [[ "$zerg1running" -eq "0" && "$zerg0running" -eq "0" ]] ; then
		error "ERROR: NEITHER ARE RUNNING"
		exit 3
	fi

	supervisorctlstatus=`supervisorctl status | grep zergling | sed 's/\s\+/ /g'`

	echo "Ok, everything looks good."
	# And again even if everything looks good, just in case.

	#influxdb_event "$user_message<br/><br/>Previous state: <pre>$supervisorctlstatus</pre>"
	StartDate=`date "+%s"`
	touch  /usr/local/galaxy/galaxy-dist/.restart-lock

	# Ok, so now we are sure that just one is running
	if [ "$zerg1running" -eq "1" ] ; then
		echo "Starting zergling 0"
		supervisorctl start gx:zergling0
		echo "Zergling 0 should be running. Now wait patiently while it starts. This script will continue when it is ready."
		while [ $(curl --silent localhost:9190 | wc -c) -eq "0" ]; do
			sleep 5;
			echo -n '.'
		done
		echo
		supervisorctl stop gx:zergling1
	elif [ "$zerg0running" -eq "1" ] ; then
		echo "Starting zergling 1"
		supervisorctl start gx:zergling1
		echo "Zergling 1 should be running. Now wait patiently while it starts. This script will continue when it is ready."
		while [ $(curl --silent localhost:9191 | wc -c) -eq "0" ]; do
			sleep 5;
			echo -n '.'
		done
		echo
		supervisorctl stop gx:zergling0
	fi

	FinalDate=`date "+%s"`
	timing=`date -u -d "0 $FinalDate seconds - $StartDate seconds" +"%H:%M:%S"`
	#influxdb_event "Swap took $timing"
	success "Swap took $timing" "galaxy,zergling"
	rm /usr/local/galaxy/galaxy-dist/.restart-lock
}

supervisor_strace() {
	task=$1
	state=$(supervisorctl status | grep $task)
	echo "$state" | grep --quiet "RUNNING"
	if (( $? > 0 )); then
		error "$task is not running"
		exit 1
	fi

	pid=$(echo $state | egrep -o 'pid ([0-9]*)' | sed 's/pid //g' | tr '\n' ' ')
	pids=$(echo "$pid"  | sed 's/^\s*//g;s/\s*$//g;s/ / -p /g')
	strace -e open -p $pids
}

assert_count() {
	if (( $1 != $2 )); then
		error "$3"
		usage
		exit 1
	fi
}

query() {
	psql -c "$1"
}

query_tsv() {
	psql -c "COPY ($1) to STDOUT with CSV DELIMITER E'\t'"
}

query_csv() {
	psql -c "COPY ($1) to STDOUT with CSV DELIMITER ','"
}

if (( $# == 0 )); then
	usage safe
fi

if [[ $1 == "validate" ]]; then ## validate: validate config files
	validate
elif [[ $1 == "zerg" ]]; then
	if [[ $2 == "swap" ]]; then ## zerg swap '<message>': swap zerglings
		validate

		if (( $# != 3 )); then
			error "Restart now requires a message"
			echo "Please call as: $0 zerg swap 'Restart due to changes in configuration'"
			exit 1
		fi

		zerg_swap $3
	elif [[ $2 == "tail" ]]; then ## zerg tail: tail zergling logs
		tail -f /var/log/galaxy/zerg*.log
	elif [[ $2 == "strace" ]]; then ## zerg strace [0|1|pool]: swap zerglings
		if [[ $3 == "pool" ]]; then
			supervisor_strace "gx:zergpool"
		elif [[ $3 == "0" ]] || [[ $3 == "1" ]]; then
			supervisor_strace "zergling$3"
		else
			supervisor_strace "gx:zerg"
		fi
	else
		error "Unknown command"
		usage
	fi
elif [[ $1 == "handler" ]]; then
    if [[ $2 == "strace" ]]; then ## handler strace <handler_id>: Run an strace on a specific handler (to watch it load files.)
		supervisor_strace "hd:handler$3"
	elif [[ $2 == "tail" ]]; then ## handler tail: tail handler logs
		tail -f /var/log/galaxy/handler*.log
	elif [[ $2 == "restart" ]]; then ## handler restart '<message>': restart handlers
		validate
		#influxdb_event "Restarting handlers"
		supervisorctl restart hd:
	else
		error "Unknown command"
		usage
	fi
elif [[ $1 == "migrate-tool-install-to-sqlite" ]]; then ## migrate-tool-install-to-sqlite: Converts normal potsgres toolshed repository tables into the SQLite version
	# Export tables
	if [[ -f  galaxy_install.sqlite ]]; then
		error "galaxy_install.sqlite exists, not overwriting"
		exit 1
	fi

	success "Creating new sqlite database: galaxy_install.sqlite"
	empty_schema=$(mktemp)
	echo "
	PRAGMA foreign_keys=OFF;
	BEGIN TRANSACTION;
	CREATE TABLE migrate_version (
		repository_id VARCHAR(250) NOT NULL,
		repository_path TEXT,
		version INTEGER,
		PRIMARY KEY (repository_id)
	);
	CREATE TABLE tool_shed_repository (
		id INTEGER NOT NULL,
		create_time DATETIME,
		update_time DATETIME,
		tool_shed VARCHAR(255),
		name VARCHAR(255),
		description TEXT,
		owner VARCHAR(255),
		changeset_revision VARCHAR(255),
		deleted BOOLEAN,
		metadata BLOB,
		includes_datatypes BOOLEAN,
		installed_changeset_revision VARCHAR(255),
		uninstalled BOOLEAN,
		dist_to_shed BOOLEAN,
		ctx_rev VARCHAR(10),
		status VARCHAR(255),
		error_message TEXT,
		tool_shed_status BLOB,
		PRIMARY KEY (id),
		CHECK (deleted IN (0, 1))
	);
	CREATE TABLE tool_version (
		id INTEGER NOT NULL,
		create_time DATETIME,
		update_time DATETIME,
		tool_id VARCHAR(255),
		tool_shed_repository_id INTEGER,
		PRIMARY KEY (id),
		FOREIGN KEY(tool_shed_repository_id) REFERENCES tool_shed_repository (id)
	);
	CREATE TABLE tool_version_association (
		id INTEGER NOT NULL,
		tool_id INTEGER NOT NULL,
		parent_id INTEGER NOT NULL,
		PRIMARY KEY (id),
		FOREIGN KEY(tool_id) REFERENCES tool_version (id),
		FOREIGN KEY(parent_id) REFERENCES tool_version (id)
	);
	CREATE TABLE migrate_tools (
		repository_id VARCHAR(255),
		repository_path TEXT,
		version INTEGER
	);
	CREATE TABLE tool_dependency (
		id INTEGER NOT NULL,
		create_time DATETIME,
		update_time DATETIME,
		tool_shed_repository_id INTEGER NOT NULL,
		name VARCHAR(255),
		version VARCHAR(40),
		type VARCHAR(40),
		status VARCHAR(255),
		error_message TEXT,
		PRIMARY KEY (id),
		FOREIGN KEY(tool_shed_repository_id) REFERENCES tool_shed_repository (id)
	);
	CREATE TABLE repository_dependency (
		id INTEGER NOT NULL,
		create_time DATETIME,
		update_time DATETIME,
		tool_shed_repository_id INTEGER NOT NULL,
		PRIMARY KEY (id),
		FOREIGN KEY(tool_shed_repository_id) REFERENCES tool_shed_repository (id)
	);
	CREATE TABLE repository_repository_dependency_association (
		id INTEGER NOT NULL,
		create_time DATETIME,
		update_time DATETIME,
		tool_shed_repository_id INTEGER,
		repository_dependency_id INTEGER,
		PRIMARY KEY (id),
		FOREIGN KEY(tool_shed_repository_id) REFERENCES tool_shed_repository (id),
		FOREIGN KEY(repository_dependency_id) REFERENCES repository_dependency (id)
	);
	CREATE INDEX ix_tool_shed_repository_name ON tool_shed_repository (name);
	CREATE INDEX ix_tool_shed_repository_deleted ON tool_shed_repository (deleted);
	CREATE INDEX ix_tool_shed_repository_tool_shed ON tool_shed_repository (tool_shed);
	CREATE INDEX ix_tool_shed_repository_changeset_revision ON tool_shed_repository (changeset_revision);
	CREATE INDEX ix_tool_shed_repository_owner ON tool_shed_repository (owner);
	CREATE INDEX ix_tool_shed_repository_includes_datatypes ON tool_shed_repository (includes_datatypes);
	CREATE INDEX ix_tool_version_tool_shed_repository_id ON tool_version (tool_shed_repository_id);
	CREATE INDEX ix_tool_version_association_tool_id ON tool_version_association (tool_id);
	CREATE INDEX ix_tool_version_association_parent_id ON tool_version_association (parent_id);
	CREATE INDEX ix_tool_dependency_tool_shed_repository_id ON tool_dependency (tool_shed_repository_id);
	CREATE INDEX ix_repository_dependency_tool_shed_repository_id ON repository_dependency (tool_shed_repository_id);
	CREATE INDEX ix_repository_repository_dependency_association_tool_shed_repository_id ON repository_repository_dependency_association (tool_shed_repository_id);
	CREATE INDEX ix_repository_repository_dependency_association_repository_dependency_id ON repository_repository_dependency_association (repository_dependency_id);
	COMMIT;
	" > ${empty_schema}
	sqlite3 galaxy_install.sqlite < ${empty_schema}
	rm ${empty_schema}

	success "Migrating tables"


	# tool_shed_repository is special :(
	table=tool_shed_repository
	success "  export: ${table}"
	export_csv=$(mktemp /tmp/tmp.gxadmin.${table}.XXXXXXXXXXX)
	psql -c "COPY (select
		id, create_time, update_time, tool_shed, name, description, owner, changeset_revision, case when deleted then 1 else 0 end, metadata, includes_datatypes, installed_changeset_revision, uninstalled, dist_to_shed, ctx_rev, status, error_message, tool_shed_status from $table) to STDOUT with CSV" > $export_csv;

	success "  import: ${table}"
	echo ".mode csv
.import ${export_csv} ${table}" | sqlite3 galaxy_install.sqlite
	if (( $? == 0 )); then
		rm ${export_csv}
	else
		error "  sql: ${export_csv}"
	fi

	sqlite3 galaxy_install.sqlite "insert into migrate_version values ('ToolShedInstall', 'lib/galaxy/model/tool_shed_install/migrate', 17)"
	# the rest are sane!
	for table in {tool_version,tool_version_association,migrate_tools,tool_dependency,repository_dependency,repository_repository_dependency_association}; do
		success "  export: ${table}"
		export_csv=$(mktemp /tmp/tmp.gxadmin.${table}.XXXXXXXXXXX)
		psql -c "COPY (select * from $table) to STDOUT with CSV" > $export_csv;

		success "  import: ${table}"
		echo ".mode csv
.import ${export_csv} ${table}" | sqlite3 galaxy_install.sqlite
		if (( $? == 0 )); then
			rm ${export_csv}
		else
			error "  sql: ${export_csv}"
		fi
	done

	success "Complete"

elif [[ $1 == *"query" ]]; then
	if [[ $2 == "latest-users" ]]; then ## {,csv,tsv}query   latest-users: 40 recently registered users
		qstr="
			SELECT id, create_time, pg_size_pretty(disk_usage), username, email
			FROM galaxy_user
			ORDER BY create_time desc
			LIMIT 40"
	elif  [[ $2 == "tool-usage" ]]; then ## {,csv,tsv}query   tool-usage: Counts of tool runs
		qstr="
			SELECT
				j.tool_id, count(*) AS count
			FROM job j
			GROUP BY j.tool_id
			ORDER BY count DESC"
	elif [[ $2 == "job-info" ]]; then ## {,csv,tsv}query   job-info <id>: Information about a specific job
		assert_count $# 3 "Missing Job ID"
		qstr="
			SELECT job.tool_id, job.state, galaxy_user.username, job.create_time, job.job_runner_name, job.job_runner_external_id
			FROM job, galaxy_user
			WHERE job.id = '$3' AND job.user_id = galaxy_user.id"
	elif [[ $2 == "datasets-created-daily" ]]; then ##           query   datasets-created-daily: The min/max/average/p95/p99 of total size of datasets created in a single day.
		qstr="
		CREATE TEMPORARY TABLE temp_queue_times AS
		select
			date_trunc('day', create_time),
			sum(total_size)
		from dataset
		group by date_trunc
		order by date_trunc desc;
		--
		select
			pg_size_pretty(min(sum)) as min,
			pg_size_pretty(avg(sum)) as avg,
			pg_size_pretty(percentile_cont(0.95) WITHIN GROUP (ORDER BY sum) ::bigint) as perc_95,
			pg_size_pretty(percentile_cont(0.99) WITHIN GROUP (ORDER BY sum) ::bigint) as perc_99,
			pg_size_pretty(max(sum)) as max
		from temp_queue_times;"
	elif [[ $2 == "queue-time" ]]; then ##           query   queue-time <tool_id>: The average/95%/99% a specific tool spends in queue state.
		assert_count $# 3 "Missing tool ID"
		qstr="
		CREATE TEMPORARY TABLE temp_queue_times AS
		select
			min(a.create_time - b.create_time) as queue_time
		from
			job_state_history as a
		inner join
			job_state_history as b
		on
			(a.job_id = b.job_id)
		where
			a.job_id in (select id from job where tool_id like '%"$3"%' and state = 'ok' and create_time > (now() - '3 months'::interval))
			and a.state = 'running'
			and b.state = 'queued'
		group by
			a.job_id
		order by
			queue_time desc
		;
		--
		select
			min(queue_time),
			percentile_cont(0.95) WITHIN GROUP (ORDER BY queue_time) as perc_95,
			percentile_cont(0.99) WITHIN GROUP (ORDER BY queue_time) as perc_99,
			max(queue_time)
		from temp_queue_times;"
	elif [[ $2 == "queue" ]]; then ## {,csv,tsv}query   queue: Brief overview of currently running jobs
		qstr="
			SELECT tool_id, state, count(*)
			FROM job
			WHERE state in ('queued', 'running')
			GROUP BY tool_id, state
			ORDER BY count desc"
	elif [[ $2 == "queue-detail" ]]; then ## {,csv,tsv}query   queue-detail [--all]: Detailed overview of running and queued jobs
		d=""
		if [[ $3 == "--all" ]]; then
			d=", 'new'"
		fi
		qstr="
			SELECT job.state, job.id, job.job_runner_external_id as extid, job.tool_id, galaxy_user.username, date_trunc('hour', (now() - job.create_time - '2 hours'::interval)) as time_since_creation
			FROM job, galaxy_user
			WHERE state in ('running', 'queued'$d) and job.user_id = galaxy_user.id
			ORDER BY state desc, time_since_creation desc"
	elif [[ $2 == "runtime-per-user" ]]; then ## {,csv,tsv}query   runtime-per-user <email>: computation time of user (by email)
		assert_count $# 3 "Missing user"
		qstr="
			SELECT sum((metric_value || ' second')::interval)
			FROM job_metric_numeric
			WHERE job_id in (
				SELECT id
				FROM job
				WHERE user_id in (
					SELECT id
					FROM galaxy_user
					where email = '$3'
				)
			) AND metric_name = 'runtime_seconds'"
	elif [[ $2 == "jobs-per-user" ]]; then ## {,csv,tsv}query   jobs-per-user <email>: Number of jobs run by a specific user
		assert_count $# 3 "Missing user"
		qstr="
			SELECT count(id)
			FROM job
			WHERE user_id in (
				SELECT id
				FROM galaxy_user
				WHERE email = '$3'
			)"
	elif [[ $2 == "recent-jobs" ]]; then ## {,csv,tsv}query   recent-jobs <hours>: Jobs run in the past <hours> (in any state)
		assert_count $# 3 "Missing hours"

		qstr="
			SELECT
				job.id, date_trunc('minute', job.create_time), job.tool_id, job.state, galaxy_user.username
			FROM job, galaxy_user
			WHERE job.create_time > (now() - '$3 hours'::interval) AND job.user_id = galaxy_user.id
			ORDER BY id desc
		"
	elif [[ $2 == "training" ]]; then ## {,csv,tsv}query   training [--all]: List known trainings
		d1=""
		d2="AND deleted = false"
		if [[ $3 == "--all" ]]; then
			d1=", deleted"
			d2=""
		fi

		qstr="
			SELECT
				substring(name from 10) as name,
				date_trunc('day', create_time)::date as created
				$d1
			FROM galaxy_group
			WHERE name like 'training-%' $d2
			ORDER BY create_time DESC
		"
	elif [[ $2 == "training-members" ]]; then ## {,csv,tsv}query   training-members <tr_id>: List users in a specific training
		assert_count $# 3 "Missing Training ID"
		# Remove training- if they used it.
		ww=$(echo "$3" | sed 's/^training-//g')
		qstr="
			SELECT
				galaxy_user.username,
				date_trunc('second', user_group_association.create_time) as joined
			FROM galaxy_user, user_group_association, galaxy_group
			WHERE galaxy_group.name = 'training-$ww'
				AND galaxy_group.id = user_group_association.group_id
				AND user_group_association.user_id = galaxy_user.id
		"
	elif [[ $2 == "training-queue" ]]; then
		assert_count $# 3 "Missing Training ID"
		# Remove training- if they used it.
		ww=$(echo "$3" | sed 's/^training-//g')
		qstr="
			SELECT
				job.state,
				job.id,
				job.job_runner_external_id AS extid,
				job.tool_id,
				galaxy_user.username,
				date_trunc('hour', job.create_time) AS created
			FROM
				job, galaxy_user
			WHERE
				state IN ('running', 'queued', 'new')
				AND job.user_id = galaxy_user.id
				AND galaxy_user.id
					IN (
							SELECT
								galaxy_user.id
							FROM
								galaxy_user, user_group_association, galaxy_group
							WHERE
								galaxy_group.name = 'training-$ww'
								AND galaxy_group.id = user_group_association.group_id
								AND user_group_association.user_id = galaxy_user.id
						)
			ORDER BY
				state DESC, created DESC;
		"
	elif [[ $2 == "disk-usage" ]]; then ## {,csv,tsv}query   disk-usage: Disk usage per object store.
		qstr="
			SELECT
				object_store_id, sum(total_size)
			FROM dataset
			WHERE NOT purged
			GROUP BY object_store_id
			ORDER BY sum DESC;
		"
	elif [[ $2 == "users-count" ]]; then ## {,csv,tsv}query   users-count: Shows sums of active/external/deleted/purged accounts
		qstr="
			SELECT
				active, external, deleted, purged, count(*) as count
			FROM
				galaxy_user
			GROUP BY
				active, external, deleted, purged
		"
	elif [[ $2 == "users-total" ]]; then ## {,csv,tsv}query   users-total: Total number of Galaxy users (incl deleted, purged, inactive)
		qstr="
			SELECT count(*) FROM galaxy_user
		"
	elif [[ $2 == "groups-list" ]]; then ## {,csv,tsv}query   groups-list: List all groups known to Galaxy
		qstr="
			SELECT
				galaxy_group.name, count(*)
			FROM
				galaxy_group, user_group_association
			WHERE
				user_group_association.group_id = galaxy_group.id
			GROUP BY name
		"
	elif [[ $2 == "collection-usage" ]]; then ## {,csv,tsv}query   collection-usage: Information about how many collections of various types are used
		qstr="
			SELECT
				collection_type, count(*)
			FROM
				dataset_collection
			GROUP BY
				collection_type;
		"
	elif [[ $2 == "ts-repos" ]]; then ## {,csv,tsv}query   ts-repos: Counts of toolshed repositories by toolshed and owner.
		qstr="
			SELECT
				tool_shed, owner, count(*)
			FROM
				tool_shed_repository
			GROUP BY
				tool_shed, owner;
		"
	elif [[ $2 == "job-history" ]]; then ## {,csv,tsv}query   job-history <id>: Job state history for a specific job
		assert_count $# 3 "Missing Job ID"
		qstr="
			SELECT
				date_trunc('second', create_time) as time,
				state
			FROM job_state_history
			WHERE job_id = $3
		"
	elif [[ $2 == "job-outputs" ]]; then ## {,csv,tsv}query   job-outputs <id>: Output datasets from a specific job
		assert_count $# 3 "Missing Job ID"
		qstr="
			SELECT
				hda.id, hda.state, hda.deleted, hda.purged, d.id, d.state, d.deleted, d.purged
			FROM job j
				JOIN job_to_input_dataset jtid
					ON j.id = jtid.job_id
				JOIN history_dataset_association hda
					ON hda.id = jtid.dataset_id
				JOIN dataset d
					ON hda.dataset_id = d.id
			WHERE j.id = $3
		"
	else
		error "Unknown query"
		usage
	fi

	if [[ $1 == "tsvquery" ]]; then
		query_tsv "$qstr"
	elif [[ $1 == "csvquery" ]]; then
		query_csv "$qstr"
	else
		query "$qstr"
	fi
elif [[ $1 == "update" ]]; then ## update: Update the script
    echo "Please run:"
    echo
    echo "curl https://raw.githubusercontent.com/usegalaxy-eu/gxadmin/master/gxadmin > $0"
elif [[ $1 == "help" ]] || [[ $1 == "-h" ]] || [[ $1 == "--help" ]]; then
	usage safe
else
	error "Unknown command"
	usage
fi
